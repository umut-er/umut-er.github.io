[
  
  {
    "title": "Bilkent CS315: A Retrospective",
    "url": "/posts/bilkent-cs315-a-retrospective/",
    "categories": "",
    "tags": "bilkent",
    "date": "2025-01-07 16:00:00 +0300",
    





    
    "snippet": "IntroductionIt has been some time since I have resolved to write and reflect on my experience taking the CS315 Programming Languages course at Bilkent University. First, I will be going over the co...",
    "content": "IntroductionIt has been some time since I have resolved to write and reflect on my experience taking the CS315 Programming Languages course at Bilkent University. First, I will be going over the content of the course, the syllabus. I will be pointing out what they get right, and, in my estimation, where there is room for improvement. Then, I will be suggesting potential improvement opportunities and proposals.I should add, however, that there is a specific reason why I am choosing to invest time into writing an article about this course, as opposed to the other courses that I am taking. I will say, right off the bat, that I did find this course overall boring, and I will also add that I felt like we could’ve learned more and more varied material in a semester. However, the primary reason that I am choosing to write is that I felt like there is a lot of missed opportunity with this course.I will be releasing this blog for public, however, you should know that I will not be trying to be expository. You might find it hard to follow if you are not familiar with the subject matter.Overview: The SyllabusThis is the syllabus of the course. Right off the bat, I want to mention that Logic Programming was omitted from the course when I took it. From what I understand, it is usually omitted from this course.The first 12 weeks are usually divided into two cycles. I will call these the lex-yacc cycle (In this syllabus it is week 1-4, however, it takes longer I believe) and the imperative programming cycle. We have the thirteenth week, about functional programming.Lex-Yacc CycleFor the lex-yacc cycle, the goal is a mini course project. In this cycle, we go over a formal way of describing programming languages. In my experience, this part of the course is woefully insufficient. We start by going over the notion of a formal grammar. First off, we need to talk about the concept of a regular expression. This is where the problem starts: We are given no reason why we should consider this specific subset of languages. Even more problematic is the concept of context-free grammar. This is explained extremely quickly, without giving any reason why it is important to consider (i.e, they are computationally very advantageous) or even what exactly they are. I would understand that these are better left to a automata theory course, but, in that case, why bring the concepts up in the first place? I guarantee, if you asked the students of this course what a context-free grammar means, you would get very inadequate answer, something like It is the BNF form.However, it is even more problematic that we spend so much time on two programs, namely, lex and yacc. At this point, the student already has the prerequisite knowledge to use lex (i.e, writing regular expressions) in order to construct a lexer, or yacc (i.e, writing BNF form context-free grammars) in order to construct a parser. However, ridiculous amounts of time are spent describing the SYNTAX of yacc. Except for conflicts, which I will come to, the syntax of these tools can be given as a reading assignment, as the students are already aware of the general theory of what these tools are implementing, at least at a surface level. Instead, we are given lectures for 2 weeks explaining the syntax for these parser tools.The parse conflicts deserve their own paragraph just because of how inadequately they are covered in the course. The conflict is not a property of a grammar, unlike ambiguity. It is generated when you try to parse a specific grammar with a parsing strategy. yacc is a LALR(1) parser. Understanding this specific parsing strategy is extremely critical to understanding the conflict this strategy will generate. However, this course doesn’t actually cover parsing in any real way (except for the syntax of yacc, which doesn’t count). The end result is a bunch of extremely confused students who are looking for ways to understand how to systematically detect conflicts for the midterm. They are out of luck, if they don’t want to read a 48 page Stanford University document that they found on the internet, none of which is covered in the class. However, without this knowledge, the best thing they can rely on is gut feeling for the midterm. In my estimation, this course doesn’t cover the conflicts at all (in any real way, anyway).To conclude, the lex-yacc cycle is very inadequate for a student who is trying to learn the material in a clear way. A lot of the rigour and detail is handwaved away, and we instead focus on the syntax of yacc (almost feels like we are back to CS101, learning Java), or some very surface level concept like that. You find students often ask whether they should put =, := or ::= in their BNF form notation, or something like that. The conflicts are the prime example of the surface level explanations in this course. The course project (lexing and parsing a language of your own creation) is an interesting and engaging experience, which is a silver-lining to the first 4-5 weeks. I just wished we were given the opportunity to be more creative. However, the grading criteria forces us to basically make a clone of C or some similar language.Imperative Programming CycleBefore explaining my issues with this part of the course, I want to mention the disconnect between the previous part and this part of the course. There is no progression of ideas from the first part to here. What you learned there will stay there, and we will move on. It is almost like the first part of this course is really more appropriate for a Compiler Design course, but I will get to that in the next section.For this section, I really don’t have a lot of constructive criticism, I will only share my experience. Let me be honest: I found this part of the course plain boring. Just reading the names of the topics, (names, bindings, scopes, data types, expressions, assignments, …) it would not be a stretch to assume that a 3rd year computer science student is at least implicitly aware of these topics (meaning they know the concept but don’t know it’s name). One has to recognize that this may cause a situation where the lectures become uninteresting for a lot of students.I want to immediately qualify my statements above. I don’t mean to say that we learn nothing from this. There are many useful ideas here: activation records and the call stacks, coroutines, closures, etc… However, in between these, there are so much that we already are familiar with.I want to also critique the homework assignments. We are asked to implement CS101 level tasks in 7 different languages. I feel like this was a relatively useless assignment. I, for one, don’t remember a single thing from any of these different languages, and I use ChatGPT less than many of my peers for homework assignments. I feel like more engaging and interesting homework assignments can be given. Here is an idea: implementing a call stack with activation records. Many of us, including me, have difficulty understanding static links and dynamic links, for example. I feel like implementing static scoping for myself using static links would’ve been very instructive, for example.In conclusion, this section of the course is, first of all, very disconnected from the first part of the course. It has large sections where we are expected to go over material we are familiar with. I think instructors of this course should use more discretion in skipping or, at least, going over very quickly the topics they feel their audiences are mostly familiar with. The homework assignments do very little to make us critically engage with the material we are learning.Functional Programming CycleIn the current form of this course, this section may as well be left out. Functional programming is a huge topic, and we are only studying it for only a single week. Instead of properly examining the computational model of functional programming, maybe doing a homework assignment or two with it, we quickly memorize some syntax of the functional programming language Scheme.Here is why I find this approach unsatisfactory for me: I didn’t know anything about this paradigm before I took this course! It was aSuggestions for Improvement"
  },
  
  {
    "title": "About the New Largest Prime Number",
    "url": "/posts/about-the-new-largest-prime-number/",
    "categories": "",
    "tags": "math, prime numbers, number theory, computation",
    "date": "2024-10-25 16:00:00 +0300",
    





    
    "snippet": "IntroductionIn October 11 2024, a new largest prime has been found by Luke Durant and the Great Internet Mersenne Prime Search (GIMPS) project [1] [2]. The number is \\(2^{136\\,279\\,841}-1\\) and it ...",
    "content": "IntroductionIn October 11 2024, a new largest prime has been found by Luke Durant and the Great Internet Mersenne Prime Search (GIMPS) project [1] [2]. The number is \\(2^{136\\,279\\,841}-1\\) and it has a whopping 41,024,320 digits. The previously known largest prime was also discovered by the same project. The number was \\(2^{82\\,589\\,933}-1\\), it had 24,862,048 digits, which is quite a bit smaller than this new one [1]. In this blog post, I explain the following:  I start by explaining some theory related to prime numbers, what they are, and how we know there are an infinite number or prime numbers.  I explain what the perfect numbers are, gradually working my way up to their relation with the so-called Mersenne primes.  I explain why the new largest primes all have the form \\(2^n-1\\) (i.e, Mersenne primes), and how they are calculated, why their calculation is more efficient than other prime calculation algotihms.Preliminaries: Prime NumbersMost people know what prime numbers are. I will nevertheless give a definition of them. Prime numbers are natural numbers greater than 1 that is not a product of two smaller natural numbers [3]. First few prime numbers are 2, 3, 5, 7…There is another important concept, being relatively prime. For two positive integers $m$ and $n$, they are called relatively prime if they have no common divisor greater than 1. For example, $15 = 3 \\cdot 5$ and 28 = $2^2\\cdot7$ are relatively prime, even though neither of them are prime by themselves.Wikipedia says that the earlies evidence of people knowing about prime numbers dates to around 1550 BCE [3]. Euclid, around 300 BCE, had quite a bit to say about prime numbers in his monumental mathematical work, Elements. Probably the most important theorem Euclid proved regarding the primes is the following:Theorem (Euclid): There are an infinite number of prime numbers.  Proof: Assume, to the contrary, that there are a finite number of prime numbers. Let them be \\(p_1, p_2, \\text{...} , p_n\\). Note that this list contains all of the prime numbers (under our assumption that there are finitely many of them). The number \\(p_1\\cdot p_2 \\cdot \\text{...} \\cdot p_n + 1\\) is not divisible by any of these prime numbers. Hence, it must also be a prime. However, we assumed that the list contained all of the primes. Therefore, there are an infinite number of prime numbers.Now we move on to another concept, the perfect numbers, which is first exposited by Euclid in his Elements. We will move on to reveal their connection with a certain class of prime numbers (also first given by Euclid, but we will go further then him on this point).Perfect Numbers and Mersenne PrimesBefore starting this topic, I would like to mention that Veritasium has a fantastic video on this topic. It explains quite a bit of the same theory I am about to explain, but I am planning to give more details and proofs for my statements, while the Veritasium video is more focused on the history.Unlike prime numbers, not everyone knows what a perfect number is. A perfect number is a positive integer that is equal to the sum of its positive proper divisors. Let me immediately follow up with two examples. $6$ is a perfect number. Its positive divisors are $1$, $2$, $3$ and $6$. We exclude $6$ itself, because it is boring. We are left with \\(6 = 1 + 2 + 3\\). This condition makes $6$ a perfect number. In a similar way, \\(28 = 1 + 2 + 4 + 7 + 14\\). Hence, $28$ is also a perfect number.In order to proceed forward it is important to introduce some notation and prove some intermediate results. We will first introduce the divisor function, \\(\\sigma(n)\\), and prove a critical result.Definition (Divisor Function) [5]: The sum of divisors is the function \\(\\begin{equation}\t\\sigma(n)=\\sum_{d\\vert n}d\\end{equation}\\)  Example: For those of you who are not familiar with the notation above, \\(\\sum_{d\\vert n}d\\) means summing all positive integers $d$ such that $d$ divides $n$. For example, \\(\\sigma(10) = 1 + 2 + 5 + 10 = 18\\). Note that, if $n$ is a perfect number, \\(\\sigma(n)=2n\\) is satisfied. This is going to be how we are going to detect perfect numbers. We now move on to prove a critical theorem about the divisor function: Theorem (Commutativity) [5]: $\\sigma(mn) = \\sigma(m)\\sigma(n)$ if $m$ and $n$ are relatively prime.  Proof: Let $m_1$, $m_2$, … , $m_k$ be the divisors of $m$ and $n_1$, $n_2$, … , $n_l$ be the divisors of $n$. Then, $\\sigma(m) = m_1 + m_2 + … + m_k$ and $\\sigma(n) = n_1 + n_2 + … + n_l$. Then, the product:\\(\\begin{equation}\t\\left(m_1 + m_2 + ... + m_k\\right)\\cdot\\left(n_1 + n_2 + ... + n_l\\right)\\end{equation}\\)  covers all the divisors of $m\\cdot n$ provided that $m$ and $n$ are relatively prime.It is not terribly important to understand this proof, but you should know that we will use this theorem in the next proof. Euclid, who is, in my opinion, the first mathematical genius, not only stated what the perfect numbers are, he gave a way to find some of them. The following is a 2300+ year old statement that still is the best way of finding perfect numbers using Mersenne primes:Theorem (Euclid 2): If $2^n-1$ is a prime number (i.e, a Mersenne prime), then $N=2^{n-1}\\left(2^n-1\\right)$ is a perfect number. Proof: We start by noting that $2^n-1$ and $2^{n-1}$ are relatively prime, since $2^n-1$ is assumed to be prime. Hence, the commutativity theorem holds. Furthermore, $\\sigma\\left(2^n-1\\right) = 2^n$ since the divisors of a prime number are $1$ and itself. We have the following:\\(\\begin{equation}\t\\sigma\\left(2^{n-1}\\left(2^n-1\\right)\\right) = \\sigma\\left(2^{n-1}\\right)\\cdot\\sigma\\left(2^n-1\\right) = \\left(2^{n}-1\\right)\\cdot2^n\\end{equation}\\)  I used the fact that $\\sigma\\left(2^{n-1}\\right) = \\left(2^{n}-1\\right)$. This is a well known identity, which you can check for yourself. Notice that, in $(3)$, \\(\\sigma(n)=2n\\) is satisfied. Hence, we established that $N$ is a perfect number.This is certainly a great result, but there is more. What we ideally want is the converse (or something like the converse, we will see) of this Euclid 2 theorem. Those of you who are not familiar with mathematical logic may struggle to understand this previous sentence. I will make a slight digression into logic and explain what the converse of a conditional statement is.Generally, theorems are given in this form: if P, then Q. This is also the case in the Euclid 2 theorem. We can write this as  $P \\implies Q$  using symbolic logic. The truth table for this is the following:\t\t\t\t\t\t$P$\t\t$Q$\t\t$$P \\implies Q$$\t\t\t\t\t\t0\t\t0\t\t1\t\t\t\t0\t\t1\t\t1\t\t\t\t1\t\t0\t\t0\t\t\t\t1\t\t1\t\t1\tThe converse of the statement if P then Q is defined as if Q, then P, which is definitely not the same statement. Let us write it in symbolic logic and give its truth table:\t\t\t\t\t\t$P$\t\t$Q$\t\t$$Q \\implies P$$\t\t\t\t\t\t0\t\t0\t\t1\t\t\t\t0\t\t1\t\t0\t\t\t\t1\t\t0\t\t1\t\t\t\t1\t\t1\t\t1\tAs you can see, they differ in some rows. The converse (?) of this Euclid 2 theorem was proved first by Leonhard Euler nearly 2000 years after Euclid proved the original statement. This shows that the converse of a theorem, if it is true, may be significantly harder to prove:Theorem (Euler): Every even perfect number $N$ can be written in the form $N=2^{n-1}\\left(2^n-1\\right)$, where $2^n-1$ is prime. Proof: See [5].I omitted the proof of this statement, since it is slightly complicated. The reference [5] gives several proofs for this theorem, including the original one by Euler.And herein lies the importance of Mersenne primes. Combining the theorems of Euler and Euclid 2, we can state that Mersenne primes (primes that can be written as $2^n-1$) generate every even perfect number using the formula $2^{n-1}\\left(2^n-1\\right)$. Learned people usually state this fact in the following way: There exists a bijection (one-to-one correspondence) between Mersenne primes and even perfect numbers.Those of you who are careful readers may have a question in there mind. Why do we say a bijection exists only with even perfect numbers? What about odd perfect numbers? This brings us to two unanswered (as of yet) questions in mathematics:  Do odd perfect numbers exist?  Are there an infinite amount of perfect numbers?I think it is clear we didnt answer the first question in any capacity in this blog post. Neither have we shown the second statement. Indeed, if we have managed to show that there exists an infinite number of primes of form $2^n-1$, we would have solved the second question, since the Mersenne primes generate perfect numbers. However, no one has managed to show this yet.Up to now, I explained some theory related to perfect numbers, which are not really relevant to the discovery of the largest prime. This section only exists to show that this new discovery also generates the largest known perfect number, which would have approximately 82,000,000 digits (Indeed, we do not need Euler’s contributions to make this statement, the Euclid 2 theorem is enough).In the next section, I will change gears and explain the following:  Preliminaries of computing (assignments and loops) and determining the efficiency of calculations (so-called Big-O notation) in a very informal way.  Approaches to calculating general primes and their efficiency. Prime sieves.  Mersenne primes and their calculation.Preliminaries: ComputingIn this informal introduction to computing, I will focus on two key concepts:  variables, assignment  loops    Variables &amp; Assignment    Variables are symbols that hold integers. They differ from usual mathematics, where variables usually take any value in some set (for example, $x\\in \\mathbb{R}$ means that $x$ can take on values in the set $\\mathbb{R}$). In computing, any variable at any time has a definite value. The symbol is just an abstraction for that value. Assignment refers to setting the value of the variable. Let’s see a concrete example:    x &lt;- 3x &lt;- 5x &lt;- 3 * 5 + 7        We have 3 assignment operations in a row. The variable x is assigned to the value of 3 at first. Then, the value of x is set to 5 and finally we set it to 24. In computing, it is sometimes useful to define collections of objects. These are referred to as arrays or lists. Giving an example:    x &lt;- [1, 2, 3]y &lt;- x[0] + x[2]        We initialize x as a collection of 3 elements. In line 2, x[0] refers to the first object in this collection, namely, 1. Therefore, y is initialized to 1 + 3 = 4.    Loops    Loops are the heart of computing. They are used to make iterative calculations. Here is an example.    x &lt;- 3while x &gt; 0 do     x &lt;- x - 1end        This is the sort of computation which is what computation is all about. The indented statement, x &lt;- x - 1, is repeated while x&gt;0. The indented statement reduces the value of x by 1. Thus, after 3 iterations, we will stop. There is another type of loop. See the following example. \\    x &lt;- 0for item in [1, 2, 3] do     x &lt;- x + itemend        y &lt;- 0z &lt;- [1, 2, 3]for item in z do     y &lt;- y + itemend        In this loop, we set the variable item is initialized to the values in the collection [1, 2, 3]. In the first iteration, we have item=1, in the second item=2 and so on. Each time, we set the value of x to be its old value plus the value of this item variable. Hence, we will have x=6 at the end. The bottom example is exactly the same thing as the top example.  After all that, we come to a more challenging part, which is computational efficiency. In the efficiency project, we are usually concerned with the size of our inputs. Lets start with two examples:input: n, a positive integeroutput: z, the sum of values up to n, i.e, 1+2+...+nz &lt;- (n * (n+1)) / 2input: n, a positive integeroutput: z, the sum of values up to n, i.e, 1+2+...+nz &lt;- 0x &lt;- 1while x &lt;= n do\tz &lt;- z + x \tx &lt;- x + 1endThese two programs calculate exactly the same value for every value of the input, n. However, notice that, in the first one, we do one multiplication and one division, regardless of how big our input (n) is. In the second one, we do n iterations of the while loop. If we assume that the computer takes t seconds to calculate the sum, we will have to wait nt seconds to get our answer. Therefore, we can say that the first calculation is more efficient than the second one. This gives rise to the notion of computational complexity. We write $O(1)$ for the efficiency of the first code, because the time for its calculation doesn’t depend on the size of the input. For the second one, we write $O(n)$ since the time it takes to complete the computation scales linearly with the size of our input. There are other time complexities such as $O(n^2)$, $O(n^3)$, $O(n\\log{n})$ and so on.Approaches to Calculate Prime NumbersLets try to imagine how we can compute if a number is prime or not. Lets see the most straightforward approach:input: n, a positive integeroutput: true, if n is prime. false, otherwisex &lt;- 1while x &lt; n do\tif n % x == 0 begin\t\treturn false\tend\tx &lt;- x + 1endreturn trueI used some symbols which I haven’t explained. First, the if statement executes the indented block if its statement is true. The statement here is n % x == 0, which evaluates to true if the remainder of the division n/x is equal to 0. There is also the symbol !=, which means not equal.The computational complexity for this program is $O(n)$. We can do better and notice that we only need to check the remainders up to the square root of the input number, which would yield a complexity of $O(\\sqrt n)$, which is quite a bit more efficient.Lets ask a different question. How efficiently can we calculate what the prime numbers are in the first $n$ natural numbers. We can certainly check each one of the $n$ numbers using our $O(\\sqrt n)$ program $n$ times, which yields a complexity of $O(n\\sqrt n)$. There exists a better method, called the Sieve of Eratosthenes, invented by the Greeks circa 200s BCE [6]. I am not interested in explaining what this algorithm is in detail, which would be a large block of text. Instead, please view this gif image I found on Wikipedia [6].Hopefully that makes it clear. This algorithm is said to have a complexity of $O(n\\log\\log n)$, which is quite a bit more efficient than our $O(n\\sqrt n)$ algorithm. There are other, more complicated and slightly more efficient sieves out there, which are very much out of scope for this blog post.Mersenne Primes and Their CalculationSo, what makes the calculation of Mersenne primes so much more efficient? The first step is to reduce the search space. With Mersenne primes, we are only iterating over the exponent $n$ (in $2^n-1$). Note that, in this newly discovered prime, the exponent is only 9 digits long, quite a bit less than the 41 million digit number it represents. Furthermore, there is another theorem, which we haven’t proved here, which states that if $2^n-1$ is a Mersenne prime, $n$ must also be a prime [7]. That further reduces the search space for $n$.Afterwards comes the costly parts. After determining a prime $n$, we must check whether this $n$ generates a Mersenne prime. There is a very efficient way of checking whether a number divides a potential Mersenne prime, given under the Trial Factoring heading in the website [7]. In general, we can determine if a number $q$ is a factor of $2^p-1$ in logarithmic time using smart algorithms. Finally, we can take into account that any potential divisor of $2^n-1$ must be of the form $2kp+1$, another theorem which we haven’t proved here.Unfortunately, none of these limitations allow us to check 42 million digit numbers. Instead, we look for a good while in order to be confident that we may have a prime, and check primality using the so called Lucas-Lehmer test, given below:Theorem (Lucas-Lehmer Primality Testing) [7]: For $p &gt; 2$, $2^p-1$ is prime if and only if $S_{p-2}$ is zero in the sequence:\\(\\begin{equation}\tS_0 = 4,\\quad S_n = \\left(S_{n-1}^2 - 2\\right) \\text{ mod } (2^p-1)\\end{equation}\\)  Proof: see [7]Note that this theorem only requires us to calculate values up to the order of the exponent, which, again is only 9 digits long, and this calculation can be made. This is the last (and probably the most important) piece in the puzzle of prime number hunting.ConclusionWow, this was quite a blog post. I hope you found it interesting and engaging. This blog post is my attempt at celebrating the work of the Great Internet Mersenne Prime Search project, which yielded the largest known prime number some days ago. I am planning to continue this blog if I have an interesting topic to talk about. I hope this blog post found you well. Cheers!NOTE: There may be errors in this post, of which I am solely responsible. Please contact me if you detect any.References[1] https://en.wikipedia.org/wiki/Largest_known_prime_number [2] https://www.mersenne.org/primes/?press=M136279841 [3] https://en.wikipedia.org/wiki/Prime_number [4] https://en.wikipedia.org/wiki/Perfect_number [5] https://jvoight.github.io/notes/perfelem-051015.pdf [6] https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes [7] https://www.mersenne.org/various/math.php"
  },
  
  {
    "title": "My Contributions to the Newt Project Part 2",
    "url": "/posts/my-contributions-to-the-newt-project-part-2/",
    "categories": "",
    "tags": "gsoc",
    "date": "2024-08-01 14:50:00 +0300",
    





    
    "snippet": "IntroductionThis is the second part of my blog post logging the contributions I made to the Newt project. You can see that post here. This blog post will go mostly into the contributions I made aft...",
    "content": "IntroductionThis is the second part of my blog post logging the contributions I made to the Newt project. You can see that post here. This blog post will go mostly into the contributions I made after the work I outlined in the first blog even though there might be some overlap. Let’s go through it:Small Bug FixesGitHub Issue There was a small bug related to loading maps on top of each other when they had certain color schemes. I found this bug and resolved it.GitHub Issue There was a small bug related to a spinner (which is a small animation indicating a load screen) that appears if we try to apply layout an empty map. This was a nice and easy fix.`Added at the time of the edit, 13th of August GitHub Issue There was a small issue with the SBGN bricks feature, which, as the name suggests, should only work with SBGN formats (specifically, PD). However, it worked with SBML also, which is not intended. I disabled this behaviour.Build BoxGithub Issue This was a suggestion by me. In web development, it is usual to have an internal server (meaning only the people working in a company have access to that server). This server occasionally gets rebuilt (which means updated with the latest changes). In our team, there was some confusion about when this server was last updated, what changes are currently on the internal server ready to be tested, etc… I suggested to include a build box that included the time of the last rebuild of the internal server. It looks like this:as you can see, in the blue portion in the middle, we have the build information.File Loading ImprovementsGitHub Issue I made two suggestions to include in the next Newt release. First one is including the spinner when we are trying to import very large files.The second one is related to the drag &amp; drop import operation. This operation previously only worked for a limited number of file formats. For the other file formats, we had to use the import menu. I added functionality so that we don’t have to use the import menu and just use the drag &amp; drop functionality. This issue was mostly resolved, but there were some concerns related to code duplication (which is when we write code that solves the same problem in different parts of the software). The remaining part of the issue was taken out of the release milestone, which just means it will be revisited in a later time.SBML UI, Palette and Legend ImprovementsGitHub Issue It was found that there were significant issues with the SBML (which is a file format) support in Newt. Couple of issues were opened about these problems, one of which is this one. This one is generally about visual enhancements for the users. It included six items to be fixed, to which I also added one. Resolving this issue was a relatively long process, which involved careful frontend work. After a lot of back and forth trying to understand and resolved the issues, we managed to completely fix this issue.I also suggested a visual update of labeling the nodes / edges in the palette. Below, you can see the old (top) and the new (bottom) imagesImport / Export Operation ImprovementsGitHub Issue I was originally not going to do this, but I was included anyway. This is the largest standing issue on this project since I have started my work. A complicated issue that encompasses a wide variety of functionalities that need to be fixed.Let me try to explain what this is. There are many file formats for doing systems biology. I went over this concept in my previous blog post. These formats can sometimes be converted to each other. In Newt, we have support for this type of functionality whenever it is possible. However, we don’t do all of this ourselves. Sometimes, we use external services to do our converting. The aim is getting a file which represents the model you have on the screen. This is broadly called exporting. Some issues were discovered with these processes.The reverse, loading an exported file into the app, is called importing. Some issues were also discovered with the import process.The biggest issue here was that we were not exporting nor importing layout information (which is related to how we show a biochemical map to our users, what goes where etc…) when we are working with the SBML file format. I was included to fix the export side of this issue. In order to learn how these formats work (by extension learning how they might be exported), you need to read technical documents called specifications. Now, those of you that are not familiar to documentations and specifications might not be aware of this, but those documents are usually long and dense. This is the SBML Level 3 Version 2 Specifications, which is 180+ pages long. The good news is that we don’t have to read all of it. We try to only read what is relevant to us (which is usually not very straightforward to determine). There are also good software packages that help us in the process. Luckily, this was the case. Even though this issue is still ongoing at the time of writing (but almost resolved at the time of the edit, -UUE), we have made major progress. I have also upgraded our app to use SBML Level 3 Version 2, which is a more thorough standard for what we want to achieve (it is also the latest).At the time of the edit, I was tasked with and resolved more items on this issue, which included a PD to SBML (and vice versa) conversion using the MINERVA service. I also implemented something called infer nesting for SBML, which is a graph algorithm to put smaller nodes inside bigger nodes.Auxiliary Box / State Information in Export / ImportGitHub Issue, GitHub Issue I have already talked about SBML export / import, which is also what the focus of this issue is. In our interpretation of the SBML format, following CellDesigner, we have auxiliary boxes. See the marked regions in the image below.These are the binding region, residue variable and the unit of information. There is also something called state information for nodes. See picture below:these are the multimer node, the active node and the hypothetical node (in that order, left to right). These information were not exported previously. I was tasked to export and import them.Now, there is a reason why I said that this was our interpretation of the SBML format. That’s because the SBML format is not exact with regards to what visual features we put on the screen. Visually representing a biochemical map is only a secondary concern with SBML. It is more concerned with the integrity of the underlying model which consists of species and reactions (broadly). The format is designed for a machine to understand and simulate whereas something like the SBGN format is designed not to simulate but to show the user what the biological model is.Why have I explained all this? Well, I want to express that there is not an exact way of storing this visual information in the SBML format even though Newt has these SBML features, which is fine. As I said, it is not an exact standard with respect to the visual features. Luckily, the people who develop this SBML format are smart people and recognize that individual softwares might want to go above and beyond what the intention of a pure SBML file would be. They include a way of annotating elements through the &lt;annotation&gt; tag. The contents of this tag can freely ignored by other software packages, which means it includes non-essential software specific information about the underlying model. This is exactly what I am trying to do with this issue.With all that out of the way, I started working on our annotation scheme. It has some rules outlined in that 180+ page document, but it is not very limiting at all (basically any valid XML with a namespace goes). I developed our format for this and implemented export / import functionality for our software. As of the writing of this blog, this issue is awaitig to be reviewed and closed (it is closed at the time of edit, -UUE).Conclusion / Future WorkWell, this was a good amount of work that I outlined. When reading through the SBML documentation, I realized that the most important feature of the SBML format is producing simulations for biochemical reactions. However, there is currently no support for this in Newt. I talked to my mentor and we agreed to talk about this after the release because it would be a long process and delay the release unnecessarily.At the time of edit, 13th of August, I have prepared a document for SBML simulation support and sent it to my mentor. I expect that the new Newt release will come sometime this month.At the time of second edit, 20th of August, we decided to move forward with the simulation features as outlined in the document. I expect that I will be working to add that feature over the course of the semester, but we will see.This blog also has more readers than I anticipated initially (Which is admittedly 0. I opened this blog mostly for documenting my work, though I am planning on expanding my scope to talk about books, mathematics or other stuff). I might add a mailing list for people who are interested in being notified when my blogs come out. I might also share an Instagram story about my blog. We will see. Definitely let me know if you are interested in a mailing list (If you are reading this, you can probably access me on either Instagram or Whatsapp).Have a lovely rest of the summer!"
  },
  
  {
    "title": "My Contributions to the Newt Project",
    "url": "/posts/my-contributions-to-the-newt-project/",
    "categories": "",
    "tags": "gsoc",
    "date": "2024-07-01 17:10:00 +0300",
    





    
    "snippet": "IntroductionSo, I have been working on the Newt project (which is a project about what is usually called “systems biology”, especially visualizing biological pathways) for about three weeks (not co...",
    "content": "IntroductionSo, I have been working on the Newt project (which is a project about what is usually called “systems biology”, especially visualizing biological pathways) for about three weeks (not counting Eid). I will go through my contributions in chronological order below.Added at the time of the edit, 20th of August Part 2 is out. You can view it here. If you are viewing this as part of GSOC final submission, you should know that part 2 also covers my work during the program. Nothing else in this blog, except those two blog posts, is part of my submission. I provide the links to specific GitHub issues in both blog posts, from which you can view the code. The issues are going to be incorporated into the upcoming Newt 4.0 release.Creating an SBML LegendGitHub Issue A “legend” is defined as the wording on a map or diagram explaining the symbols used for those of you who are not familiar with that sense of the word. SBML stands for Systems Biology Markup Language which is linked with something called CellDesigner. None of these are terribly important for you to know fully. Here is a quick explanation:SBML is a way to define and show biochemical reactions with certain signs such that there is very little confusion about the meaning of the symbols. A legend is a document (briefly) explaining these symbols and their meanings. Here is the official CellDesigner legend:.I was tasked with making a similar legend and integrating it to the application. I came up with this:This was then integrated into the application. It now looks like this:                                                              Your browser does not support the video tag. Here is a    link to the video file instead.    Overall, I would say that this was a relatively simple although somewhat time consuming task since I had to create this image using inkscape, which was not something I was familiar with.Query HighlightingGitHub Issue There exists a database called PathwayCommons which contains a lot of biological pathways and interactions (mainly between genes). These database services have what’s called an API (stands for Application Programming Interface). What an API allows us to do is asking these services some data (in this case, it is giving us information about pathways). In Newt, there is an interface which allows us to make API requests (that is, asking a web service for some information) and display the result in a user friendly way. Here is a demonstratiton (warning: most of this video is the load screen, feel free to move to the 20s-25s mark):                                                              Your browser does not support the video tag. Here is a    link to the video file instead.    I was tasked with color coding this output so that it is more clear what is going on. I will skip over the details of how I did it (and causing a temporary crash on the internal server…) and just show you the result. Below is what comes out after the same query in the video:There are also more colorful queries, especially ones with both source and target nodes (understanding these terms are not relevant). Here is another picture (this one is a more complicated query between BRCA1 and BRCA2):Underlay HighlightingGitHub Issue Well, in order to show the previous one, I had to show you this one as well, so, brief let me be. Newt originally had a highlight feature. It looked like this:After my implementations, it looks like this:This is a better highlighter for a couple of reasons:  It is visually more appealing and apparent.  It doesn’t interfere with situations where the color of the edges have significance.Map Type Display on TabsGitHub Issue We already talked about how we represent maps with symbols and legends. However, people have come up with different sets of symbols and legends over the years. Newt currently implements PD (process description), AF (activity flow), SIF (simple interaction format), SBML (systems biology markup language) and a combination of these. Every image that I can generate has uses at least one (possibly a combination of) the symbols of these dialects. This is called the “type” of the map. Previously, we could see the type of the map from the sidebar:After my visual changes, this is now how it looks (pay extra attention to the blue parts in the previous picture):As you can see, there is some visual change in the blue marked parts (marked in the previous picture). First of all, the map type is now shown on the tabs on the bottom right. Also, there is now a shadow effect on the tabs (in both blue marked places). This is technically called a box-shadow, which enhances the visuals.About Some Small BugsGitHub Issue A bug is defined as an error in a computer program or system. During my time working on the Newt project, I also found some issues with the works of other people working there. I don’t want to go into details, suffice it to say that there was some weird behavior with a pop-up panel. I pointed this out and also helped in implementing the ideal behavior for smoother user experience.GitHub Issue There was a small issue related to map loading that I fixed as well.Query Result SimplificationGitHub Issue Remember this picture?Well, there is a problem. It’s big. It’s huge. It contains a lot of excess information. So, there was an idea on simplifying some of these extra bits of pieces. We do that by removing the nodes that we see as excess. We developed an algorithm (defined as a process or set of rules to be followed in calculations) on how to select what goes and what remains. The algorithm is a bit complicated to explain in this post, but ultimately not very complicated at all. What you should know is that the way we decide is not random. The things that go have to satisfy a certain level of simplicity (meaning that nothing complicated is lost). Without further yapping, let me present you with the simplified version of the same query:still complicated, but noticably simpler. Here is an extra picture on the nodes that we decide to delete with this algorithm (anything that is highlighted in blue means that it is going away):Closing RemarksHope this was a fun and easy read! I tried to make this piece as accessible as I can for the general public, which is not how I wrote the first two more technical posts. Anyhow, these document my changes (as of the date of publication) which is contained in the GitHub record in 7-8 issues and 2-3 pull requests. I think this was a productive couple of weeks for me, and my mentor seems to like my work as well. Currently I am reading about computer algebra, which is a computational/mathematical theory about making a computer solve mathematical problems (such as integration, think WolframAlpha if you are familiar with that). It’s a struggle… But maybe in the future (very future) a blog post about that may come out. Also, I included a Hamlet quotation in this post. Can you figure that out?"
  }
  
]

